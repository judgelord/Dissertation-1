---
title: "05-campaign_ads"
author: "Pete Erickson"
date: "2/15/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r, include = FALSE, echo = FALSE}
library("here")       # file paths
library("tidyverse")  # workhorse package
library("tidylog")
library("kableExtra")
library("knitr")
library("ggdag")
library("dagitty")
library("gridExtra")
library("broom")
library("dplyr")
library("reshape2")
library("stargazer")
library("rstatix")
library("lme4")
library("brglm")
library("bucky")
library("haven")
library("writexl")
library("lubridate")
```

# Notes for Data Cleaning

In this document, I have essentially cleaned 5 x data sets containing information about various presidential campaign television advertisements contained in the 2000 - 2016 Elections. 

As each data set is unique, I have taken care to standardize the data sets and prepare them in such a way so as to facilitate future coding. In the paragraphs to follow, I first outline the procedures taken before embarking on these coding procedures and tasks.  

The first cleaning of data began in March of 2021.  At this time, I was only interested in analyzing the individual advertisements; that is, I simply wanted to count the distinct number of advertisements made and aired in each election cycle, and analyze these specific advertisements at the ad level.  This analysis occurred mainly from March of 2021 - December 2021. 

In February of 2022, however, I was directed by my dissertation committee to embark on an additional analysis of the airings of the advertisements. This is different from the first analysis because in analyzing the "airings" rather than the "ads," the goal instead was to examine which ads were aired on which markets, at what frequency, etc. This document is the document that I used to clean and organize the data.  It is a substantial and lengthy document, and quite detailed.  

This document proceeds in three main parts.  The first part is the culmination of cleaning work to produce a consolidated data set of the individual advertisements. The second part is the cleaning of an airings level analysis which is then merged with the first data set after edits had been made on the advertisement level. In both parts, I take many notes in the hopes that I would be able to follow these procedures myself, later down the road, or if other ever wanted to build upon this work here.    

## The Data 

Data from the 2016 and 2012 data sets came from the Wesleyan Media Project (WMP), whereas the data from the 2008, 2004, and 2000 data sets came from the Wisconsin Advertising Project (WiscAd). Each data set is structured somewhat differently. One can detect a fairly straightforward improvement each subsequent election, i.e. the 2000 data is the "roughest," and the data improves each year.  

## Results as of 20 February 2022

In this paragraph, I briefly highlight some notable points about the data. 

## Important Files and Filenames

# Section 1: Forming an Ad-Level Data Set

In this section, I clean 5 x separate data sets, beginning with the 2016 data set and working backwards to the 2000 data set.   

```{r data2016, include=FALSE, echo=FALSE, warning=FALSE}

# This section of code "cleans" the data used from the 2016 data set.  

# first read in the data and then summarize it
df_2016 <- read_dta(here("data", "wmp-pres-2016-v1.1.dta"))
summary(df_2016)


#Get an initial idea for how many ads there are are, which ones to watch, split. 
# Coding to find the Total # of Ads: 914
dfsplit  <- df %>% select(creative, issue60, issue61, issue62, issue64, issue65, issue66, issue67, issue68, issue69, issue70, issue71, issue72, issue73, issue74) %>% distinct() %>% view()

#Ads to watch : 252
dfsplit_watch <- dfsplit %>% filter(issue60==1 | issue61==1 |issue62==1 | issue64==1 | issue65==1 |issue66==1 | issue67==1 | issue68==1 | issue69==1 | issue70==1 | issue71==1 | issue72==1 | issue73==1 | issue74==1) %>% view()

# Ads to not watch : 659
dfsplit_dontwatch <- dfsplit %>% filter(issue60 !=1 & issue61 !=1 & issue62 !=1 & issue64 !=1 & issue65 !=1 & issue66 !=1 & issue67 !=1 & issue68 !=1 & issue69 !=1 & issue70 !=1 & issue71 != 1 & issue72 !=1 & issue73 !=1 & issue74 !=1) %>% view()

# Ads that are coded as NA for all of these issue areas: 3
dfsplit_NA <- dfsplit %>% filter(is.na(issue60) & is.na(issue61) & is.na(issue62) & is.na(issue64) & is.na(issue65) & is.na(issue66) & is.na(issue67) & is.na(issue68) & is.na(issue69) & is.na(issue70) & is.na(issue71) & is.na(issue72) & is.na(issue73) & is.na(issue74)) %>% view()



# Now create a df by filtering and then grouping by the ID of the advertisement (variable "creative")
robustdf <- df %>% filter(issue60==1 | issue61==1 |issue62==1 | issue64==1 | issue65==1 |issue66==1 | issue67==1 | issue68==1 | issue69==1 | issue70==1 | issue71==1 | issue72==1 | issue73==1 | issue74==1) %>% group_by(issue60, issue61, issue62, issue64, issue65, issue66, issue67, issue68, issue69, issue70, issue71, issue72, issue73, issue74, creative) %>% count(creative) %>% view()


# begin forming a clean data set for 2016 that can be merged with other data across the years
# step 1: filter the data using the filter command by issue area 
# step 2: select the appropriate variables to include in the data using the 'select' verb
# step 3: group the results using the 'group_by' verb

clean_df_2016 <- df %>% 
  filter(issue60==1 | issue61==1 |issue62==1 | issue64==1 | issue65==1 |issue66==1 | issue67==1 | issue68==1 | issue69==1 | issue70==1 | issue71==1 | issue72==1 | issue73==1 | issue74==1) %>% 
  select(creative, l, election, tonecmag, sponsorcmag, party, sponsor, f_mention, f_picture, f_narrate, o_mention, o_picture, ad_tone, prty_mn, issue60, issue61, issue62, issue64, issue65, issue66, issue67, issue68, issue69, issue70, issue71, issue72, issue73, issue74) %>%
  group_by(creative) %>% view()


# initial cut at a data set to join to other data sets.
# I've already selected which issue areas matter, so I can drop those here and 
# because these issue areas will change over time. 
# Next, I can group by the variables I am interested in. 
# Then, I create a variable for count, referring to the number of times an ad was run
# in a particular election cycle, and an ad for the election cycle more generally. 
# I then use the "distinct" function to keep only the unique rows that matter, which is key. 
# Then I rearrange the data and display it according to descending "count" order. 

initial_2016_join <- clean_df_2016 %>% 
  select(-issue60, -issue61,-issue62, -issue64, -issue65, -issue66, -issue67, -issue68, -issue69, -issue70, -issue71, -issue72, -issue73, -issue74) %>% 
  group_by(creative, l, party, sponsor) %>%
  mutate(
    count = n(), 
    year=2016
  ) %>% 
distinct() %>% 
  select(year, count, creative:prty_mn) %>% 
  arrange(desc(count)) %>% 
  view()

df_2016 <- initial_2016_join %>% select (-election, -tonecmag, -sponsorcmag) %>% view()
# total of 252 ads to watch


##########Unlikely Ads ###########

# the following paragraph is one line of code that enabled me to gather the vital variables for when I developed the master imagery list
# it handles the variables that I need to do a meaningul comparison for the ads that are unlikely to feature military imagery
unprob_df_2016 <- df %>% 
  filter((issue60 !=1 & issue61 !=1 & issue62 !=1 & issue64 !=1 & issue65 !=1 & issue66 !=1 & issue67 !=1 & issue68 !=1 & issue69 !=1 & issue70 !=1 & issue71 != 1 & issue72 !=1 & issue73 !=1 & issue74 !=1) | (is.na(issue60) & is.na(issue61) & is.na(issue62) & is.na(issue64) & is.na(issue65) & is.na(issue66) & is.na(issue67) & is.na(issue68) & is.na(issue69) & is.na(issue70) & is.na(issue71) & is.na(issue72) & is.na(issue73) & is.na(issue74))) %>% 
  select(creative, l, election, tonecmag, sponsorcmag, party, sponsor, f_mention, f_picture, f_narrate, o_mention, o_picture, ad_tone, prty_mn, issue60, issue61, issue62, issue64, issue65, issue66, issue67, issue68, issue69, issue70, issue71, issue72, issue73, issue74) %>% 
  group_by(creative, l) %>% 
  mutate(
    count = n(), 
    year=2016
  ) %>% 
  distinct() %>% 
  select(year, count, creative, l, party, sponsor, f_mention, f_picture, f_narrate, o_mention, o_picture, ad_tone, prty_mn) %>% 
  arrange(desc(count)) %>% distinct() %>% 
  view()

## this list above includes 662 total ads, including three that were "N/A" on all pertinent issue areas

# below is the list that is "unprobable" to contain the ads I think I need to watch
clean_df_2016_unprobably <- df %>% 
  filter(issue60 !=1 & issue61 !=1 & issue62 !=1 & issue64 !=1 & issue65 !=1 & issue66 !=1 & issue67 !=1 & issue68 !=1 & issue69 !=1 & issue70 !=1 & issue71 != 1 & issue72 !=1 & issue73 !=1 & issue74 !=1) %>% 
  select(creative, l, party, issue60, issue61, issue62, issue64, issue65, issue66, issue67, issue68, issue69, issue70, issue71, issue72, issue73, issue74) %>%
  group_by(creative)

initial_2016_join_unprobable <- clean_df_2016_unprobably %>% 
  group_by(creative, l) %>%
  mutate(
    count = n(), 
    year=2016
  ) %>% 
distinct() %>% 
  select(year, count, creative, l, party, issue60, issue61, issue62, issue64, issue65, issue66, issue67, issue68, issue69, issue70, issue71, issue72, issue73, issue74) %>% 
  arrange(desc(count)) %>% 
  view()


# 659 ads to NOT watch

df_2016_notlikely <- initial_2016_join_unprobable %>% select(-issue60, -issue61, -issue62, -issue64, -issue65, -issue66, -issue67, -issue68, -issue69, -issue70, -issue71, -issue72, -issue73, -issue74) %>% view()

#total of 659 not to watch

```


```{r data2012, include=FALSE, echo=FALSE, warning=FALSE}

# read in the data and then summarize it
df_2012 <- read_dta(here("data", "wmp-pres-2012-v1.2_compress.dta"))
summary(df_2012)


#Get an initial idea for how many ads there are are, which ones to watch, split. 
df_2012_split  <- df2012 %>% select(creative, issue60, issue61, issue62, issue64, issue65, issue66, issue67, issue68, issue69, issue70, issue71, issue72) %>% distinct() %>% view()
# Coding to find the Total # of Ads: 735

df_2012_split_watch <- df_2012_split %>% filter(issue60==1 | issue61==1 |issue62==1 | issue64==1 | issue65==1 |issue66==1 | issue67==1 | issue68==1 | issue69==1 | issue70==1 | issue71==1 | issue72==1) %>% view()
#Ads to watch : 102

df_2012_split_dontwatch <- df_2012_split %>% filter(issue60 !=1 & issue61 !=1 & issue62 !=1 & issue64 !=1 & issue65 !=1 & issue66 !=1 & issue67 !=1 & issue68 !=1 & issue69 !=1 & issue70 !=1 & issue71 != 1 & issue72 !=1) %>% view()
# Ads to not watch : 622

df_2012_split_NA <- df_2012_split %>% filter(is.na(issue60) & is.na(issue61) & is.na(issue62) & is.na(issue64) & is.na(issue65) & is.na(issue66) & is.na(issue67) & is.na(issue68) & is.na(issue69) & is.na(issue70) & is.na(issue71) & is.na(issue72)) %>% view()
#Ads that are N/A or not coded: 11



# create a robust df by filtering and then grouping by the ID of the advertisement (variable "creative")
robustdf2012 <- df2012 %>% filter(issue60==1 | issue61==1 | issue62==1 | issue64==1 | issue65==1 | issue66==1 | issue67==1 | issue68==1 | issue69==1 | issue70==1 | issue71==1 | issue72==1) %>% group_by(issue60, issue61, issue62, issue64, issue65, issue66, issue67, issue68, issue69, issue70, issue71, issue72, creative) %>% count(creative) %>% view()
# count - 102


# begin forming a clean data set for 2012 that can be merged with other data across the years
# step 1: filter the data using the filter command by appropriate issue area 
# step 2: select the appropriate variables to include in the data using the 'select' verb
# step 3: group the results using the 'group_by' verb
clean_df_2012 <- df2012 %>% 
  filter(issue60==1 | issue61==1 | issue62==1 | issue64==1 | issue65==1 | issue66==1 | issue67==1 | issue68==1 | issue69==1 | issue70==1 | issue71==1 | issue72==1) %>% 
  select(creative, l, election, tonecmag, sponsorcmag, affiliation, sponsorwmp, f_mention, f_picture, f_narrate, o_mention, o_picture, ad_tone, prty_mn, issue60, issue61, issue62, issue64, issue65, issue66, issue67, issue68, issue69, issue70, issue71, issue72) %>% 
  group_by(creative) %>% view()


# initial cut at a data set to join to other data sets.
# I've already selected which issue areas matter, so I can drop those here and 
# because these issue areas will change over time. 
# Next, I can group by the variables I am interested in. 
# Then, I create a variable for count, referring to the number of times an ad was run
# in a particular election cycle, and an ad for the election cycle more generally. 
# I then use the "distinct" function to keep only the unique rows that matter, which is key. 
# Then I rearrange the data and display it according to descending "count" order. 

initial_2012_join <- clean_df_2012 %>% 
  select(-issue60, -issue61, -issue62, -issue64, -issue65, -issue66, -issue67, -issue68, -issue69, -issue70, -issue71, -issue72) %>% 
  group_by(creative, l, affiliation, sponsorwmp, prty_mn) %>%
  mutate(
    count = n(), 
    year=2012
  ) %>% 
distinct() %>% 
  select(year, count, creative:prty_mn) %>% 
  arrange(desc(count)) %>% 
  view()

# 107 ads to watch

df_2012 <- initial_2012_join %>% 
  select(-election, -tonecmag, -sponsorcmag) %>% 
  rename(party=affiliation, sponsor=sponsorwmp) %>% view()




##########################Not Likely############

# the following paragraph is one line of code that enabled me to gather the vital variables for when I developed the master imagery list
# it handles the variables that I need to do a meaningul comparison for the ads that are unlikely to feature military imagery
unprob_df_2012 <- df2012 %>% 
  filter((issue60 !=1 & issue61 !=1 & issue62 !=1 & issue64 !=1 & issue65 !=1 & issue66 !=1 & issue67 !=1 & issue68 !=1 & issue69 !=1 & issue70 !=1 & issue71 != 1 & issue72 !=1) | (is.na(issue60) & is.na(issue61) & is.na(issue62) & is.na(issue64) & is.na(issue65) & is.na(issue66) & is.na(issue67) & is.na(issue68) & is.na(issue69) & is.na(issue70) & is.na(issue71) & is.na(issue72))) %>% 
  select(creative, l, election, tonecmag, sponsorcmag, affiliation, sponsorwmp, f_mention, f_picture, f_narrate, o_mention, o_picture, ad_tone, prty_mn, issue60, issue61, issue62, issue64, issue65, issue66, issue67, issue68, issue69, issue70, issue71, issue72) %>% 
  group_by(creative, l) %>% 
  mutate(
    count = n(), 
    year=2012
  ) %>% 
  distinct() %>% 
  select(year, count, creative, l, affiliation, sponsorwmp, f_mention, f_picture, f_narrate, o_mention, o_picture, ad_tone, prty_mn) %>% 
  arrange(desc(count)) %>% rename(party=affiliation, sponsor=sponsorwmp) %>% distinct() %>% 
  view()


# below is the list that is "unprobable" to contain the ads I think I need to watch
clean_df_2012_unprobably <- df2012 %>% 
  filter(issue60 !=1 & issue61 !=1 & issue62 !=1 & issue64 !=1 & issue65 !=1 & issue66 !=1 & issue67 !=1 & issue68 !=1 & issue69 !=1 & issue70 !=1 & issue71 != 1 & issue72 !=1) %>% 
  select(creative, l, affiliation, issue60, issue61, issue62, issue64, issue65, issue66, issue67, issue68, issue69, issue70, issue71, issue72) %>%
  group_by(creative)

initial_2012_join_unprobable <- clean_df_2012_unprobably %>% 
  group_by(creative, l) %>%
  mutate(
    count = n(), 
    year=2012
  ) %>% 
distinct() %>% 
  select(year, count, creative, l, affiliation, issue60, issue61, issue62, issue64, issue65, issue66, issue67, issue68, issue69, issue70, issue71, issue72) %>% 
  arrange(desc(count)) %>% 
  rename(party=affiliation) %>% 
  view()

# 672 ads to NOT watch

df_2012_notlikely <- initial_2012_join_unprobable %>% select(-issue60, -issue61, -issue62, -issue64, -issue65, -issue66, -issue67, -issue68, -issue69, -issue70, -issue71, -issue72) %>% view()

```

```{r data2008, include=FALSE, echo=FALSE, warning=FALSE}
# Issues in General are coded differently than WMP data from 2012 and 2016


# read in the data and then summarize it
df_2008 <- read_dta(here("data", "WiscAds2008_Presidential.dta"))
summary(df_2008)
table(list(df2008$market)) %>% view()

# create an airings-based df for 2008 to be joined with others later
df_2008_airings <- df2008 %>% select(date, creative, market, station, l)
df_2008_airings <- df_2008_airings %>% mutate(
  dma=0, 
  Elec_Cycle=2008
) %>% select(-date)
summary(df_2008_airings)



#Get an initial idea for how many ads there are are, which ones to watch, split. 
df_2008_split  <- df2008 %>% select(creative, defpolicy, vets, SEPT11, terror, iraq, surge, mideast, iran, afghan, DEF_NIRQ, ISSUE_IRAQ, FOR_NIRQ, nukes, china) %>% distinct() %>% view()
# Coding to find the Total # of Ads: 934



df_2008_split_watch <- df_2008_split %>% filter(defpolicy==1 | vets==1 | SEPT11==1 | terror ==1 | iraq ==1 | surge ==1 | mideast ==1 | iran ==1 | afghan ==1 | DEF_NIRQ == 1 | ISSUE_IRAQ == 1 | FOR_NIRQ == 1 | nukes == 1 | china == 1) %>% view()
#Ads to watch : 255

df_2008_split_dontwatch <- df_2008_split %>% filter(defpolicy!=1 & vets!=1 & SEPT11!=1 & terror !=1 & iraq !=1 & surge !=1 & mideast !=1 & iran !=1 & afghan !=1 & DEF_NIRQ != 1 & ISSUE_IRAQ != 1 & FOR_NIRQ != 1 & nukes != 1 & china != 1) %>% view()
# Ads to not watch : 679

df_2008_split_NA <- df_2008_split %>% filter(is.na(defpolicy) & is.na(vets) & is.na(SEPT11) & is.na(terror) & is.na(iraq) & is.na(surge) & is.na(mideast) & is.na(iran) & is.na(afghan) & is.na(DEF_NIRQ) & is.na(ISSUE_IRAQ) & is.na(FOR_NIRQ) & is.na(nukes) & is.na(china)) %>% view()
#Ads that are N/A or not coded: 0



# create a larger df by filtering and then grouping by the ID of the advertisement (variable "creative")

robustdf2008 <- df2008 %>% filter(defpolicy==1 | vets==1 | SEPT11==1 | terror ==1 | iraq ==1 | surge ==1 | mideast ==1 | iran ==1 | afghan ==1 | DEF_NIRQ == 1 | ISSUE_IRAQ == 1 | FOR_NIRQ == 1 | nukes == 1 | china == 1) %>% group_by(defpolicy, vets, SEPT11, terror, iraq, surge, mideast, iran, afghan, DEF_NIRQ, ISSUE_IRAQ, FOR_NIRQ, nukes, china, creative) %>% count(creative) %>% view()
#count - 255

# begin forming a clean data set for 2008 that can be merged with other data across the years
# step 1: filter the data using the filter command by appropriate issue area 
# step 2: select the appropriate variables to include in the data using the 'select' verb
# step 3: group the results using the 'group_by' verb
clean_df_2008 <- df2008 %>% 
  filter(defpolicy==1 | vets==1 | SEPT11==1 | terror ==1 | iraq ==1 | surge ==1 | mideast ==1 | iran ==1 | afghan ==1 | DEF_NIRQ == 1 | ISSUE_IRAQ == 1 | FOR_NIRQ == 1 | nukes == 1 | china == 1) %>% 
  select(creative, l, GROUP_NA, party, sponsor, FC_MNTN, FC_APER, OP_MNTN, AD_TONE, PRTY_MN, defpolicy, vets, SEPT11, terror, iraq, surge, mideast, iran, afghan, DEF_NIRQ, ISSUE_IRAQ, FOR_NIRQ, nukes, china) %>% 
  group_by(creative) %>% view()

# initial cut at a data set to join to other data sets.
# I've already selected which issue areas matter, so I can drop those here and 
# because these issue areas will change over time. 
# Next, I can group by the variables I am interested in. 
# Then, I create a variable for count, referring to the number of times an ad was run
# in a particular election cycle, and an ad for the election cycle more generally. 
# I then use the "distinct" function to keep only the unique rows that matter, which is key. 
# Then I rearrange the data and display it according to descending "count" order. 

initial_2008_join <- clean_df_2008 %>% 
  select(-defpolicy, -vets, -SEPT11, -terror, -iraq, -surge, -mideast, -iran, -afghan, -DEF_NIRQ, -ISSUE_IRAQ, -FOR_NIRQ, -nukes, -china) %>%
  group_by(creative, l, party) %>%
  mutate(
    count = n(), 
    year=2008
  ) %>% 
distinct() %>% 
  select(year, count, creative:PRTY_MN) %>% 
  arrange(desc(count)) %>% 
  view()
#260 total ads

# drop the "GROUP_NA" variable
df_2008_almost <- initial_2008_join %>% select(-GROUP_NA) %>% view()

# now use the mutate function to create multiple
#variables
#recode values of sponsor to match the 2012 and 2016 schemes (flip 4 and 3)

df_2008 <- df_2008_almost %>% mutate(
  f_mention=case_when(FC_MNTN==1 | FC_MNTN==3 | FC_MNTN==4 | FC_MNTN==5 ~ 1,
                      FC_MNTN==0 | FC_MNTN==2 | FC_MNTN==98 | FC_MNTN==99 ~ 0),
  f_picture=case_when(FC_MNTN==2 | FC_MNTN==3 | FC_APER==1 | FC_APER==2 ~ 1, 
                      FC_APER==0 | FC_APER==98 | FC_APER==99 | FC_MNTN != 2 | FC_MNTN != 3 ~ 0),
  f_narrate=case_when(FC_APER==1 | FC_APER==2 ~ 1, 
                      FC_APER == 0 | FC_APER==98 | FC_APER==99 ~ 0),
  o_mention=case_when(OP_MNTN == 1 | OP_MNTN ==3 ~ 1,
                      OP_MNTN ==0 | OP_MNTN==2 | OP_MNTN == 98 | OP_MNTN ==99 ~ 0),
  o_picture=case_when(OP_MNTN==2 | OP_MNTN==3 ~1,
                      OP_MNTN==0 | OP_MNTN==1 | OP_MNTN==98 | OP_MNTN==99 ~ 0),
  party=case_when(party==1 ~ "DEMOCRAT",
                  party==2 ~ "REPUBLICAN",
                  party != 1 | party!=2 ~ "OTHER"),
  sponsor=case_when(sponsor==1~1,
                    sponsor==2 ~2,
                    sponsor==3~4,
                    sponsor==4~3
                    )
  ) %>% 
  select(-FC_MNTN, -FC_APER, -OP_MNTN) %>% 
  relocate(AD_TONE, PRTY_MN, .after = o_picture) %>% 
  rename(ad_tone=AD_TONE, prty_mn=PRTY_MN) %>% 
  view()

# 260 total ads


###########UNLIKELY####################

# the following paragraph is one line of code that enabled me to gather the vital variables for when I developed the master imagery list
# it handles the variables that I need to do a meaningul comparison for the ads that are unlikely to feature military imagery
unprob_df_2008 <- df2008 %>% 
  filter(defpolicy!=1 & vets!=1 & SEPT11!=1 & terror !=1 & iraq !=1 & surge !=1 & mideast !=1 & iran !=1 & afghan !=1 & DEF_NIRQ != 1 & ISSUE_IRAQ != 1 & FOR_NIRQ != 1 & nukes != 1 & china != 1) %>% 
  select(creative, l, GROUP_NA, party, sponsor, FC_MNTN, FC_APER, OP_MNTN, AD_TONE, PRTY_MN) %>% 
  group_by(creative, l) %>% mutate(
    count = n(), 
    year=2008,
    f_mention=case_when(FC_MNTN==1 | FC_MNTN==3 | FC_MNTN==4 | FC_MNTN==5 ~ 1,
                      FC_MNTN==0 | FC_MNTN==2 | FC_MNTN==98 | FC_MNTN==99 ~ 0),
  f_picture=case_when(FC_MNTN==2 | FC_MNTN==3 | FC_APER==1 | FC_APER==2 ~ 1, 
                      FC_APER==0 | FC_APER==98 | FC_APER==99 | FC_MNTN != 2 | FC_MNTN != 3 ~ 0),
  f_narrate=case_when(FC_APER==1 | FC_APER==2 ~ 1, 
                      FC_APER == 0 | FC_APER==98 | FC_APER==99 ~ 0),
  o_mention=case_when(OP_MNTN == 1 | OP_MNTN ==3 ~ 1,
                      OP_MNTN ==0 | OP_MNTN==2 | OP_MNTN == 98 | OP_MNTN ==99 ~ 0),
  o_picture=case_when(OP_MNTN==2 | OP_MNTN==3 ~1,
                      OP_MNTN==0 | OP_MNTN==1 | OP_MNTN==98 | OP_MNTN==99 ~ 0),
  party=case_when(party==1 ~ "DEMOCRAT",
                  party==2 ~ "REPUBLICAN",
                  party != 1 | party!=2 ~ "OTHER"),
  sponsor=case_when(sponsor==1~1,
                    sponsor==2 ~2,
                    sponsor==3~4,
                    sponsor==4~3
                    )
  ) %>% 
  distinct() %>% 
  arrange(desc(count)) %>% 
  select(-FC_MNTN, -FC_APER, -OP_MNTN, -GROUP_NA) %>% 
  relocate(AD_TONE, PRTY_MN, .after = o_picture) %>% 
  rename(ad_tone=AD_TONE, prty_mn=PRTY_MN) %>% 
  select(year, count, creative, party, sponsor, f_mention, f_picture, f_narrate, o_mention, o_picture, ad_tone, prty_mn) %>% group_by(creative) %>% distinct() %>% view()


# below is the list that is "unprobable" to contain the ads I think I need to watch
clean_df_2008_unprobably <- df2008 %>% 
  filter(defpolicy!=1 & vets!=1 & SEPT11!=1 & terror !=1 & iraq !=1 & surge !=1 & mideast !=1 & iran !=1 & afghan !=1 & DEF_NIRQ != 1 & ISSUE_IRAQ != 1 & FOR_NIRQ != 1 & nukes != 1 & china != 1) %>% 
  select(creative, l, party, defpolicy, vets, SEPT11, terror, iraq, surge, mideast, iran, afghan, DEF_NIRQ, ISSUE_IRAQ, FOR_NIRQ, nukes, china) %>% mutate(
    party=case_when(party==1 ~ "DEMOCRAT",
                  party==2 ~ "REPUBLICAN",
                  party != 1 | party!=2 ~ "OTHER")
  ) %>% group_by(creative)

initial_2008_join_unprobable <- clean_df_2008_unprobably %>% 
  group_by(creative, l) %>%
  mutate(
    count = n(), 
    year=2008
  ) %>% 
distinct() %>% 
  select(year, count, creative, l, party, defpolicy, vets, SEPT11, terror, iraq, surge, mideast, iran, afghan, DEF_NIRQ, ISSUE_IRAQ, FOR_NIRQ, nukes, china) %>% 
  arrange(desc(count)) %>% 
  view()

# 706 ads to NOT watch

df_2008_notlikely <- initial_2008_join_unprobable %>% select(-defpolicy, -vets, -SEPT11, -terror, -iraq, -surge, -mideast, -iran, -afghan, -DEF_NIRQ, -ISSUE_IRAQ, -FOR_NIRQ, -nukes, -china) %>% view()



```

```{r}
# NOT RUN {
dfex <- tibble(
  x = sample(10, 100, rep = TRUE),
  y = sample(10, 100, rep = TRUE)
)
dfex %>% view()

nrow(dfex)
nrow(distinct(dfex))
nrow(distinct(dfex, x, y))

distinct(dfex, x)
distinct(dfex, y)

# Can choose to keep all other variables as well
distinct(df, x, .keep_all = TRUE)
distinct(df, y, .keep_all = TRUE)

# You can also use distinct on computed variables
distinct(df, diff = abs(x - y))

# The same behaviour applies for grouped data frames
# except that the grouping variables are always included
df <- tibble(
  g = c(1, 1, 2, 2),
  x = c(1, 1, 2, 1)
) %>% group_by(g)
df %>% distinct()
df %>% distinct(x)

# Values in list columns are compared by reference, this can lead to
# surprising results
tibble(a = as.list(c(1, 1, 2))) %>% glimpse() %>% distinct()
tibble(a = as.list(1:2)[c(1, 1, 2)]) %>% glimpse() %>% distinct()
# }
```


```{r data2004, include=FALSE, echo=FALSE, warning=FALSE}
# WiscAd Data; slight difference from 2008 data

#EISSUE: if coded 50 - then Defense/Military
#ESSUE: if coded 51 - Missile Defense/Star Wars; 
#EISSUE: if coded 52 - Veterans
#EISSUE: if coded 53 - Foreign Policy
#EISSUE: if coded 54 - Bosnia
#EISSUE: if coded 55 - China
#EISSUE: if coded 57 - terrorism
#EISSUE: if coded 58 - Middle East;
# EISSUE: if coded 59 - Afghanistan; 
#EISSUE: if coded 83 - September 11
# A total of 10 x topic areas plus 
# 2 x explicit mention variables () ESEPT11, eterror  )

# read in the data and then summarize it
df_2004 <- read_dta(here("data", "WiscAds_2004 Presidential.dta"))
summary(df_2004)
df_2004 %>% filter(market=="Charleston") %>% select(market, station) %>% view()
table(list(df2004$market)) %>% view()




#Get an initial idea for how many ads there are are, which ones to watch, split. 
df_2004_split  <- df2004 %>% select(creative, EISSUE1, EISSUE2, EISSUE3, EISSUE4, ESEPT11, eterror, EACTOR1, EACTOR2, EACTOR3, EACTOR90, ecfcred, EISSUE90) %>% distinct() %>% view()
# Coding to find the Total # of Ads: 644

df_2004_split_watch <- df_2004_split %>% filter(EISSUE1 == 50 | EISSUE1 == 51 | EISSUE1 == 52 | EISSUE1 == 53 | EISSUE1 == 54 | EISSUE1 == 55 | EISSUE1 == 57 | EISSUE1 == 58 | EISSUE1 == 59 | EISSUE1 == 83 | EISSUE2 == 50 | EISSUE2 == 51 | EISSUE2 == 52 | EISSUE2 == 53 | EISSUE2 == 54 | EISSUE2 == 55 | EISSUE2 == 57 | EISSUE2 == 58 | EISSUE2 == 59 | EISSUE2 == 83 | EISSUE3 == 50 | EISSUE3 == 51 | EISSUE3 == 52 | EISSUE3 == 53 | EISSUE3 == 54 | EISSUE3 == 55 | EISSUE3 == 57 | EISSUE3 == 58 | EISSUE3 == 59 | EISSUE3 == 83 | EISSUE4 == 50 | EISSUE4 == 51 | EISSUE4 == 52 | EISSUE4 == 53 | EISSUE4 == 54 | EISSUE4 == 55 | EISSUE4 == 57 | EISSUE4 == 58 | EISSUE4 == 59 | EISSUE4 == 83 | ESEPT11==1 | eterror==1) %>% view()
#Ads to watch : 185


### several weeks after coding of ads began, I adjust the selection criteria to include 
# three variables I had initially missed.
# the first of these is the family of 'EACTOR' variables (1, 2, 3, and 90)...these variables
# measures who features prominently in the ad, one of which is a response for
# military personnel.  
# The second variable is ECFCRED, which is the source of credibility of 
# the actor in the variable, which can take the value of 'military'
# After including these associated variables, I conduct a further analysis. 
# Finally, thereis also a variable called EISSUE90, which is a "catch all," but I noticed that one 
# of these ads took the value of "iraq"

df_2004_split_watch_revised <- df_2004_split %>% filter(EISSUE1 == 50 | EISSUE1 == 51 | EISSUE1 == 52 | EISSUE1 == 53 | EISSUE1 == 54 | EISSUE1 == 55 | EISSUE1 == 57 | EISSUE1 == 58 | EISSUE1 == 59 | EISSUE1 == 83 | EISSUE2 == 50 | EISSUE2 == 51 | EISSUE2 == 52 | EISSUE2 == 53 | EISSUE2 == 54 | EISSUE2 == 55 | EISSUE2 == 57 | EISSUE2 == 58 | EISSUE2 == 59 | EISSUE2 == 83 | EISSUE3 == 50 | EISSUE3 == 51 | EISSUE3 == 52 | EISSUE3 == 53 | EISSUE3 == 54 | EISSUE3 == 55 | EISSUE3 == 57 | EISSUE3 == 58 | EISSUE3 == 59 | EISSUE3 == 83 | EISSUE4 == 50 | EISSUE4 == 51 | EISSUE4 == 52 | EISSUE4 == 53 | EISSUE4 == 54 | EISSUE4 == 55 | EISSUE4 == 57 | EISSUE4 == 58 | EISSUE4 == 59 | EISSUE4 == 83 | ESEPT11==1 | eterror==1 | EACTOR1 ==16 | EACTOR2 == 16 | EACTOR3 ==16 | EACTOR90=="family of soldiers" | ecfcred==13 | EISSUE90=="IRAQ") %>% view()
#Ads to watch : 239 revised ads

df_2004_split_dontwatch <- df_2004_split %>% filter(EISSUE1 != 50 & EISSUE1 != 51 & EISSUE1 != 52 & EISSUE1 != 53 & EISSUE1 != 54 & EISSUE1 != 55 & EISSUE1 != 57 & EISSUE1 != 58 & EISSUE1 != 59 & EISSUE1 != 83 & EISSUE2 != 50 & EISSUE2 != 51 & EISSUE2 != 52 & EISSUE2 != 53 & EISSUE2 != 54 & EISSUE2 != 55 & EISSUE2 != 57 & EISSUE2 != 58 & EISSUE2 != 59 & EISSUE2 != 83 & EISSUE3 != 50 & EISSUE3 != 51 & EISSUE3 != 52 & EISSUE3 != 53 & EISSUE3 != 54 & EISSUE3 != 55 & EISSUE3 != 57 & EISSUE3 != 58 & EISSUE3 != 59 & EISSUE3 != 83 & EISSUE4 != 50 & EISSUE4 != 51 & EISSUE4 != 52 & EISSUE4 != 53 & EISSUE4 != 54 & EISSUE4 != 55 & EISSUE4 != 57 & EISSUE4 != 58 & EISSUE4 != 59 & EISSUE4 != 83 & ESEPT11!=1 & eterror!=1) %>% view()
# Ads to not watch : 455

df_2004_split_NA <- df_2004_split %>% filter(is.na(EISSUE1) & is.na(EISSUE2) & is.na(EISSUE3) & is.na(EISSUE4) & is.na(ESEPT11) & is.na(eterror)) %>% view()
#Ads that are N/A or not coded: 2


# a more robust version of ads, if we include:
robustdf2004 <- df2004 %>% filter(EISSUE1 == 50 | EISSUE1 == 51 | EISSUE1 == 52 | EISSUE1 == 53 | EISSUE1 == 54 | EISSUE1 == 55 | EISSUE1 == 57 | EISSUE1 == 58 | EISSUE1 == 59 | EISSUE1 == 83 | EISSUE2 == 50 | EISSUE2 == 51 | EISSUE2 == 52 | EISSUE2 == 53 | EISSUE2 == 54 | EISSUE2 == 55 | EISSUE2 == 57 | EISSUE2 == 58 | EISSUE2 == 59 | EISSUE2 == 83 | EISSUE3 == 50 | EISSUE3 == 51 | EISSUE3 == 52 | EISSUE3 == 53 | EISSUE3 == 54 | EISSUE3 == 55 | EISSUE3 == 57 | EISSUE3 == 58 | EISSUE3 == 59 | EISSUE3 == 83 | EISSUE4 == 50 | EISSUE4 == 51 | EISSUE4 == 52 | EISSUE4 == 53 | EISSUE4 == 54 | EISSUE4 == 55 | EISSUE4 == 57 | EISSUE4 == 58 | EISSUE4 == 59 | EISSUE4 == 83 | ESEPT11==1 | eterror==1) %>% group_by(EISSUE1, EISSUE2, EISSUE3, EISSUE4, ESEPT11, eterror, creative) %>% count(creative) %>% view()
#count 185

# revised df, with additional selection criteria
robustdf2004_revised <- df2004 %>% filter(EISSUE1 == 50 | EISSUE1 == 51 | EISSUE1 == 52 | EISSUE1 == 53 | EISSUE1 == 54 | EISSUE1 == 55 | EISSUE1 == 57 | EISSUE1 == 58 | EISSUE1 == 59 | EISSUE1 == 83 | EISSUE2 == 50 | EISSUE2 == 51 | EISSUE2 == 52 | EISSUE2 == 53 | EISSUE2 == 54 | EISSUE2 == 55 | EISSUE2 == 57 | EISSUE2 == 58 | EISSUE2 == 59 | EISSUE2 == 83 | EISSUE3 == 50 | EISSUE3 == 51 | EISSUE3 == 52 | EISSUE3 == 53 | EISSUE3 == 54 | EISSUE3 == 55 | EISSUE3 == 57 | EISSUE3 == 58 | EISSUE3 == 59 | EISSUE3 == 83 | EISSUE4 == 50 | EISSUE4 == 51 | EISSUE4 == 52 | EISSUE4 == 53 | EISSUE4 == 54 | EISSUE4 == 55 | EISSUE4 == 57 | EISSUE4 == 58 | EISSUE4 == 59 | EISSUE4 == 83 | ESEPT11==1 | eterror==1 | EACTOR1 ==16 | EACTOR2 == 16 | EACTOR3 ==16 | EACTOR90=="family of soldiers" | ecfcred==13 | EISSUE90=="IRAQ") %>% group_by(EISSUE1, EISSUE2, EISSUE3, EISSUE4, ESEPT11, eterror, EACTOR1, EACTOR2, EACTOR3, EACTOR90, ecfcred, EISSUE90, creative) %>% count(creative) %>% view()
#count 239

# revised dontwatch list
df_2004_split_dontwatch_revised <- df_2004_split %>% filter(EISSUE1 != 50 & EISSUE1 != 51 & EISSUE1 != 52 & EISSUE1 != 53 & EISSUE1 != 54 & EISSUE1 != 55 & EISSUE1 != 57 & EISSUE1 != 58 & EISSUE1 != 59 & EISSUE1 != 83 & EISSUE2 != 50 & EISSUE2 != 51 & EISSUE2 != 52 & EISSUE2 != 53 & EISSUE2 != 54 & EISSUE2 != 55 & EISSUE2 != 57 & EISSUE2 != 58 & EISSUE2 != 59 & EISSUE2 != 83 & EISSUE3 != 50 & EISSUE3 != 51 & EISSUE3 != 52 & EISSUE3 != 53 & EISSUE3 != 54 & EISSUE3 != 55 & EISSUE3 != 57 & EISSUE3 != 58 & EISSUE3 != 59 & EISSUE3 != 83 & EISSUE4 != 50 & EISSUE4 != 51 & EISSUE4 != 52 & EISSUE4 != 53 & EISSUE4 != 54 & EISSUE4 != 55 & EISSUE4 != 57 & EISSUE4 != 58 & EISSUE4 != 59 & EISSUE4 != 83 & ESEPT11!=1 & eterror!=1 & EACTOR1 !=16 & EACTOR2 != 16 & EACTOR3 !=16 & EACTOR90!="family of soldiers" & ecfcred!=13 & EISSUE90!="IRAQ") %>% view()
# REvised Ads to not watch : 399




# begin forming a clean data set for 2004 that can be merged with other data across the years
# step 1: filter the data using the filter command by appropriate issue area 
# step 2: select the appropriate variables to include in the data using the 'select' verb
# step 3: group the results using the 'group_by' verb
clean_df_2004 <- df2004 %>% 
  filter(EISSUE1 == 50 | EISSUE1 == 51 | EISSUE1 == 52 | EISSUE1 == 53 | EISSUE1 == 54 | EISSUE1 == 55 | EISSUE1 == 57 | EISSUE1 == 58 | EISSUE1 == 59 | EISSUE1 == 83 | EISSUE2 == 50 | EISSUE2 == 51 | EISSUE2 == 52 | EISSUE2 == 53 | EISSUE2 == 54 | EISSUE2 == 55 | EISSUE2 == 57 | EISSUE2 == 58 | EISSUE2 == 59 | EISSUE2 == 83 | EISSUE3 == 50 | EISSUE3 == 51 | EISSUE3 == 52 | EISSUE3 == 53 | EISSUE3 == 54 | EISSUE3 == 55 | EISSUE3 == 57 | EISSUE3 == 58 | EISSUE3 == 59 | EISSUE3 == 83 | EISSUE4 == 50 | EISSUE4 == 51 | EISSUE4 == 52 | EISSUE4 == 53 | EISSUE4 == 54 | EISSUE4 == 55 | EISSUE4 == 57 | EISSUE4 == 58 | EISSUE4 == 59 | EISSUE4 == 83 | ESEPT11==1 | eterror==1) %>% 
  select(creative, spotleng, Party, Sponsor, EFC_MNTN, EFC_APER, EOP_MNTN, EAD_TONE, EPRTY_MN, EISSUE1, EISSUE2, EISSUE3, EISSUE4, ESEPT11, eterror) %>% 
  group_by(creative) %>% view()

## revised

clean_df_2004_revised <- df2004 %>% 
  filter(EISSUE1 == 50 | EISSUE1 == 51 | EISSUE1 == 52 | EISSUE1 == 53 | EISSUE1 == 54 | EISSUE1 == 55 | EISSUE1 == 57 | EISSUE1 == 58 | EISSUE1 == 59 | EISSUE1 == 83 | EISSUE2 == 50 | EISSUE2 == 51 | EISSUE2 == 52 | EISSUE2 == 53 | EISSUE2 == 54 | EISSUE2 == 55 | EISSUE2 == 57 | EISSUE2 == 58 | EISSUE2 == 59 | EISSUE2 == 83 | EISSUE3 == 50 | EISSUE3 == 51 | EISSUE3 == 52 | EISSUE3 == 53 | EISSUE3 == 54 | EISSUE3 == 55 | EISSUE3 == 57 | EISSUE3 == 58 | EISSUE3 == 59 | EISSUE3 == 83 | EISSUE4 == 50 | EISSUE4 == 51 | EISSUE4 == 52 | EISSUE4 == 53 | EISSUE4 == 54 | EISSUE4 == 55 | EISSUE4 == 57 | EISSUE4 == 58 | EISSUE4 == 59 | EISSUE4 == 83 | ESEPT11==1 | eterror==1 | EACTOR1 ==16 | EACTOR2 == 16 | EACTOR3 ==16 | EACTOR90=="family of soldiers" | ecfcred==13 | EISSUE90=="IRAQ") %>% 
  select(creative, spotleng, Party, Sponsor, EFC_MNTN, EFC_APER, EOP_MNTN, EAD_TONE, EPRTY_MN, EISSUE1, EISSUE2, EISSUE3, EISSUE4, ESEPT11, eterror, EACTOR1, EACTOR2, EACTOR3, EACTOR90, ecfcred, EISSUE90) %>% 
  group_by(creative) %>% view()


# initial cut at a data set to join to other data sets.
# I've already selected which issue areas matter, so I can drop those here and 
# because these issue areas will change over time. 
# Next, I can group by the variables I am interested in. 
# Then, I create a variable for count, referring to the number of times an ad was run
# in a particular election cycle, and an ad for the election cycle more generally. 
# I then use the "distinct" function to keep only the unique rows that matter, which is key. 
# Then I rearrange the data and display it according to descending "count" order. 

initial_2004_join <- clean_df_2004 %>% 
  select(-EISSUE1, -EISSUE2, -EISSUE3, -EISSUE4, -ESEPT11, -eterror) %>% 
  group_by(creative, spotleng, Party) %>%
  mutate(
    count = n(), 
    year=2004
  ) %>% 
distinct() %>% 
  select(year, count, creative:EPRTY_MN) %>% 
  arrange(desc(count)) %>% 
  view()
# 191 Ads

#revised

initial_2004_join_revised <- clean_df_2004_revised %>% 
  select(-EISSUE1, -EISSUE2, -EISSUE3, -EISSUE4, -ESEPT11, -eterror, -EACTOR1, -EACTOR2, -EACTOR3, -EACTOR90, -ecfcred, -EISSUE90) %>% 
  group_by(creative, spotleng, Party) %>%
  mutate(
    count = n(), 
    year=2004
  ) %>% 
distinct() %>% 
  select(year, count, creative:EPRTY_MN) %>% 
  arrange(desc(count)) %>% 
  view()
# 246 Ads


# use mutate function to create multiple variables to match 2012/2016 schemes
#recode values of sponsor and adtone to match the 2012 and 2016 schemes (flip 4 and 3)
df_2004 <- initial_2004_join %>% mutate(
  f_mention=case_when(EFC_MNTN==1 | EFC_MNTN==3 | EFC_MNTN==4 | EFC_MNTN==5 ~ 1,
                      EFC_MNTN==0 | EFC_MNTN==2 | EFC_MNTN==98 | EFC_MNTN==99 ~ 0),
  f_picture=case_when(EFC_MNTN==2 | EFC_MNTN==3 | EFC_APER==1 | EFC_APER==2 ~ 1, 
                      EFC_APER==0 | EFC_APER==98 | EFC_APER==99 | EFC_MNTN != 2 | EFC_MNTN != 3 ~ 0),
  f_narrate=case_when(EFC_APER==1 | EFC_APER==2 ~ 1, 
                      EFC_APER == 0 | EFC_APER==98 | EFC_APER==99 ~ 0),
  o_mention=case_when(EOP_MNTN == 1 | EOP_MNTN ==3 ~ 1,
                      EOP_MNTN ==0 | EOP_MNTN==2 | EOP_MNTN == 98 | EOP_MNTN ==99 ~ 0),
  o_picture=case_when(EOP_MNTN==2 | EOP_MNTN==3 ~1,
                      EOP_MNTN==0 | EOP_MNTN==1 | EOP_MNTN==98 | EOP_MNTN==99 ~ 0),
  ad_tone=case_when(EAD_TONE == 2 ~1,
                    EAD_TONE == 3 ~ 2,
                    EAD_TONE == 1 ~ 3,
                    EAD_TONE <= 98 ~4),
  Party=case_when(Party==1 ~ "DEMOCRAT",
                  Party==2 ~ "REPUBLICAN",
                  Party != 1 | Party!=2 ~ "OTHER"),
  sponsor=case_when(Sponsor==1 ~ 1,
                    Sponsor ==2 ~2,
                    Sponsor ==3 ~4,
                    Sponsor ==4 ~3 )
  )%>% 
  select(-EFC_MNTN, -EFC_APER,-EOP_MNTN, -EAD_TONE, -Sponsor) %>% 
  relocate(EPRTY_MN, .after = ad_tone) %>% 
  rename(
    l=spotleng,
    party=Party,
    prty_mn=EPRTY_MN
  ) %>% 
  relocate(sponsor, .after = party) %>% 
  view()

# 191 ads to watch

df_2004_revised <- initial_2004_join_revised %>% mutate(
  f_mention=case_when(EFC_MNTN==1 | EFC_MNTN==3 | EFC_MNTN==4 | EFC_MNTN==5 ~ 1,
                      EFC_MNTN==0 | EFC_MNTN==2 | EFC_MNTN==98 | EFC_MNTN==99 ~ 0),
  f_picture=case_when(EFC_MNTN==2 | EFC_MNTN==3 | EFC_APER==1 | EFC_APER==2 ~ 1, 
                      EFC_APER==0 | EFC_APER==98 | EFC_APER==99 | EFC_MNTN != 2 | EFC_MNTN != 3 ~ 0),
  f_narrate=case_when(EFC_APER==1 | EFC_APER==2 ~ 1, 
                      EFC_APER == 0 | EFC_APER==98 | EFC_APER==99 ~ 0),
  o_mention=case_when(EOP_MNTN == 1 | EOP_MNTN ==3 ~ 1,
                      EOP_MNTN ==0 | EOP_MNTN==2 | EOP_MNTN == 98 | EOP_MNTN ==99 ~ 0),
  o_picture=case_when(EOP_MNTN==2 | EOP_MNTN==3 ~1,
                      EOP_MNTN==0 | EOP_MNTN==1 | EOP_MNTN==98 | EOP_MNTN==99 ~ 0),
  ad_tone=case_when(EAD_TONE == 2 ~1,
                    EAD_TONE == 3 ~ 2,
                    EAD_TONE == 1 ~ 3,
                    EAD_TONE <= 98 ~4),
  Party=case_when(Party==1 ~ "DEMOCRAT",
                  Party==2 ~ "REPUBLICAN",
                  Party != 1 | Party!=2 ~ "OTHER"),
  sponsor=case_when(Sponsor==1 ~ 1,
                    Sponsor ==2 ~2,
                    Sponsor ==3 ~4,
                    Sponsor ==4 ~3 )
  )%>% 
  select(-EFC_MNTN, -EFC_APER,-EOP_MNTN, -EAD_TONE, -Sponsor) %>% 
  relocate(EPRTY_MN, .after = ad_tone) %>% 
  rename(
    l=spotleng,
    party=Party,
    prty_mn=EPRTY_MN
  ) %>% 
  relocate(sponsor, .after = party) %>% 
  view()

# 246 ads to watch



###########UNLIKELY##############

# the following paragraph is one line of code that enabled me to gather the vital variables for when I developed the master imagery list
# it handles the variables that I need to do a meaningul comparison for the ads that are unlikely to feature military imagery
unprob_df_2004 <- df2004 %>% 
  filter(EISSUE1 != 50 & EISSUE1 != 51 & EISSUE1 != 52 & EISSUE1 != 53 & EISSUE1 != 54 & EISSUE1 != 55 & EISSUE1 != 57 & EISSUE1 != 58 & EISSUE1 != 59 & EISSUE1 != 83 & EISSUE2 != 50 & EISSUE2 != 51 & EISSUE2 != 52 & EISSUE2 != 53 & EISSUE2 != 54 & EISSUE2 != 55 & EISSUE2 != 57 & EISSUE2 != 58 & EISSUE2 != 59 & EISSUE2 != 83 & EISSUE3 != 50 & EISSUE3 != 51 & EISSUE3 != 52 & EISSUE3 != 53 & EISSUE3 != 54 & EISSUE3 != 55 & EISSUE3 != 57 & EISSUE3 != 58 & EISSUE3 != 59 & EISSUE3 != 83 & EISSUE4 != 50 & EISSUE4 != 51 & EISSUE4 != 52 & EISSUE4 != 53 & EISSUE4 != 54 & EISSUE4 != 55 & EISSUE4 != 57 & EISSUE4 != 58 & EISSUE4 != 59 & EISSUE4 != 83 & ESEPT11!=1 & eterror!=1 & EACTOR1 !=16 & EACTOR2 != 16 & EACTOR3 !=16 & EACTOR90!="family of soldiers" & ecfcred!=13 & EISSUE90!="IRAQ") %>% 
  select(creative, spotleng, Party, Sponsor, EFC_MNTN, EFC_APER, EOP_MNTN, EAD_TONE, EPRTY_MN, EISSUE1, EISSUE2, EISSUE3, EISSUE4, ESEPT11, eterror, EACTOR1, EACTOR2, EACTOR3, EACTOR90, ecfcred, EISSUE90) %>% 
  group_by(creative, spotleng, Party) %>% mutate(
    count = n(), 
    year=2004,
    f_mention=case_when(EFC_MNTN==1 | EFC_MNTN==3 | EFC_MNTN==4 | EFC_MNTN==5 ~ 1,
                      EFC_MNTN==0 | EFC_MNTN==2 | EFC_MNTN==98 | EFC_MNTN==99 ~ 0),
  f_picture=case_when(EFC_MNTN==2 | EFC_MNTN==3 | EFC_APER==1 | EFC_APER==2 ~ 1, 
                      EFC_APER==0 | EFC_APER==98 | EFC_APER==99 | EFC_MNTN != 2 | EFC_MNTN != 3 ~ 0),
  f_narrate=case_when(EFC_APER==1 | EFC_APER==2 ~ 1, 
                      EFC_APER == 0 | EFC_APER==98 | EFC_APER==99 ~ 0),
  o_mention=case_when(EOP_MNTN == 1 | EOP_MNTN ==3 ~ 1,
                      EOP_MNTN ==0 | EOP_MNTN==2 | EOP_MNTN == 98 | EOP_MNTN ==99 ~ 0),
  o_picture=case_when(EOP_MNTN==2 | EOP_MNTN==3 ~1,
                      EOP_MNTN==0 | EOP_MNTN==1 | EOP_MNTN==98 | EOP_MNTN==99 ~ 0),
  ad_tone=case_when(EAD_TONE == 2 ~1,
                    EAD_TONE == 3 ~ 2,
                    EAD_TONE == 1 ~ 3,
                    EAD_TONE <= 98 ~4),
  Party=case_when(Party==1 ~ "DEMOCRAT",
                  Party==2 ~ "REPUBLICAN",
                  Party != 1 | Party!=2 ~ "OTHER"),
  sponsor=case_when(Sponsor==1 ~ 1,
                    Sponsor ==2 ~2,
                    Sponsor ==3 ~4,
                    Sponsor ==4 ~3 )
  ) %>% 
  distinct() %>% 
  arrange(desc(count)) %>% 
  rename(
    l=spotleng,
    party=Party,
    prty_mn=EPRTY_MN
  )%>% 
  select(year, count, creative, l, party, sponsor, f_mention, f_picture, f_narrate, o_mention, o_picture, ad_tone, prty_mn) %>%  
  view()

unprob_df_2004 %>% select(creative) %>% distinct() %>% view() 


# below is the list that is "unprobable" to contain the ads I think I need to watch


clean_df_2004_unprobably <- df2004 %>% 
  filter(EISSUE1 != 50 & EISSUE1 != 51 & EISSUE1 != 52 & EISSUE1 != 53 & EISSUE1 != 54 & EISSUE1 != 55 & EISSUE1 != 57 & EISSUE1 != 58 & EISSUE1 != 59 & EISSUE1 != 83 & EISSUE2 != 50 & EISSUE2 != 51 & EISSUE2 != 52 & EISSUE2 != 53 & EISSUE2 != 54 & EISSUE2 != 55 & EISSUE2 != 57 & EISSUE2 != 58 & EISSUE2 != 59 & EISSUE2 != 83 & EISSUE3 != 50 & EISSUE3 != 51 & EISSUE3 != 52 & EISSUE3 != 53 & EISSUE3 != 54 & EISSUE3 != 55 & EISSUE3 != 57 & EISSUE3 != 58 & EISSUE3 != 59 & EISSUE3 != 83 & EISSUE4 != 50 & EISSUE4 != 51 & EISSUE4 != 52 & EISSUE4 != 53 & EISSUE4 != 54 & EISSUE4 != 55 & EISSUE4 != 57 & EISSUE4 != 58 & EISSUE4 != 59 & EISSUE4 != 83 & ESEPT11!=1 & eterror!=1) %>% 
  select(creative, spotleng, Party, EISSUE1, EISSUE2, EISSUE3, EISSUE4, ESEPT11, eterror) %>%
  group_by(creative) %>% view()

initial_2004_join_unprobable <- clean_df_2004_unprobably %>% 
  group_by(creative, spotleng) %>%
  mutate(
    count = n(), 
    year=2004,
    Party=case_when(Party==1 ~ "DEMOCRAT",
                  Party==2 ~ "REPUBLICAN",
                  Party != 1 | Party!=2 ~ "OTHER")
  ) %>% 
distinct() %>% 
  select(year, count, creative, spotleng, Party, EISSUE1, EISSUE2, EISSUE3, EISSUE4, ESEPT11, eterror) %>% rename(party=Party) %>% arrange(desc(count)) %>% 
  view()

# 462 ads to NOT watch

df_2004_notlikely <- initial_2004_join_unprobable %>% 
  select(-EISSUE1, -EISSUE2, -EISSUE3, -EISSUE4, -ESEPT11, -eterror) %>% 
  rename(
    l=spotleng
    ) %>% view()


```


```{r data2000, include=FALSE, echo=FALSE, warning=FALSE}
# WiscAd Data; slight difference from 2004 data
# instead of creative, title of ad called "custitle"




#q32-35 deal with campaign themes: 

# 50 - Defense
# 51 - missile defense/star wars; 
# 52 - Veterans
# 53 - Foreign Policy
# 54 - Bosnia; 
# 55 - China;
# 59 - Other defense/foreign policy issues
# 7 total issues


# read in the data and then summarize it
df_2000 <- read_dta(here("data", "Political Advertising in 2000.dta"))
# filter only by presidential ads (q3==95)
df_2000 <- df_2000 %>% filter(q3==95)
summary(df_2000)

table(list(df_2000$marketlo)) %>% view()

# create an airings-based df for 2000 to be joined with others later.  


# this data is different from the other data sets in that it
# includes advertisements from multiple types of races (house, senate, President, etc.)
# Must therefore first filter for Presidential 
# as of 1 September 21, I am trimming down races to only presidential issues (where q3==95). Previously, q3 could also == 80 or 99
# where 80 == issue advocacy or 99 == OTHER

#Get an initial idea for how many ads there are are, which ones to watch, split. 
df_2000_split  <- df2000 %>% select(custitle, q3, q32, q33, q34, q35) %>% 
  filter(q3 == 95) %>% 
  distinct() %>% view()
# Coding to find the Total # of Presidential Ads: 344

# ads coded as "Issue Advocacy"
df_2000_issue <- df2000 %>% filter(q3 == 80) %>% select(custitle, q3, q32, q33, q34, q35) %>% distinct() %>% view()

df_2000_split_watch <- df_2000_split %>% filter(q32 == 50 | q33 == 50 | q34 == 50 | q35 == 50 | q32 == 51 | q33 == 51 | q34 == 51 | q35 == 51 | q32 == 52 | q33 == 52 | q34 == 52 | q35 == 52 | q32 == 53 | q33 == 53 | q34 == 53 | q35 == 53 | q32 == 54 | q33 == 54 | q34 == 54 | q35 == 54 | q32 == 55 | q33 == 55 | q34 == 55 | q35 == 55 | q32 == 59 | q33 == 59 | q34 == 59 | q35 == 59) %>% view()
#Ads to watch : 17

df_2000_split_dontwatch <- df_2000_split %>% filter(q32 != 50 & q33 != 50 & q34 != 50 & q35 != 50 & q32 != 51 & q33 != 51 & q34 != 51 & q35 != 51 & q32 != 52 & q33 != 52 & q34 != 52 & q35 != 52 & q32 != 53 & q33 != 53 & q34 != 53 & q35 != 53 & q32 != 54 & q33 != 54 & q34 != 54 & q35 != 54 & q32 != 55 & q33 != 55 & q34 != 55 & q35 != 55 & q32 != 59 & q33 != 59 & q34 != 59 & q35 != 59) %>% view()
# Ads to not watch : 327

# Therefore, Iam only interested in viewing/coding 327+17 ads = 344 total. 

# begin forming a clean data set for 2004 that can be merged with other data across the years
# step 1: filter the data using the filter command by appropriate issue area 
# step 2: select the appropriate variables to include in the data using the 'select' verb
# step 3: group the results using the 'group_by' verb
clean_df_2000 <- df2000 %>% 
  filter(q32 == 50 | q33 == 50 | q34 == 50 | q35 == 50 | q32 == 51 | q33 == 51 | q34 == 51 | q35 == 51 | q32 == 52 | q33 == 52 | q34 == 52 | q35 == 52 | q32 == 53 | q33 == 53 | q34 == 53 | q35 == 53 | q32 == 54 | q33 == 54 | q34 == 54 | q35 == 54 | q32 == 55 | q33 == 55 | q34 == 55 | q35 == 55 | q32 == 59 | q33 == 59 | q34 == 59 | q35 == 59) %>% 
  select(custitle, len, q5, sponsor, q3, q12, q13, q14, q15, q20, q21, q22, q32, q33, q34, q35) %>% 
  filter(q3 == 95) %>% group_by(custitle) %>% view()


# initial cut at a data set to join to other data sets.
# I've already selected which issue areas matter, so I can drop those here and 
# because these issue areas will change over time. 
# Next, I can group by the variables I am interested in. 
# Then, I create a variable for count, referring to the number of times an ad was run
# in a particular election cycle, and an ad for the election cycle more generally. 
# I then use the "distinct" function to keep only the unique rows that matter, which is key. 
# Then I rearrange the data and display it according to descending "count" order. 

initial_2000_join <- clean_df_2000 %>% 
  select(-q3, -q32, -q33, -q34, -q35) %>% 
  group_by(custitle, len, sponsor) %>%
  mutate(
    count = n(), 
    year=2000
  ) %>% 
distinct() %>% 
  select(year, count, custitle:q22) %>% 
  arrange(desc(count)) %>% 
  view()
# 18 ads


# below, I create several variables (using other, similar existing variables) 
# to match existing variables in the 2012 and 2016 data sets.  
# these variables include f_mention, f_picture, f_narrate, o_mention, o_picture
# ad_tone, prty_mn, Party, and sponsor.

df_2000 <- initial_2000_join %>% mutate(
  f_mention=case_when(q12== 1 | q12== 4 ~ 1,
                      q12==0 | q12 ==3 ~ 0),
  f_picture=case_when(q12==2 | q12==4 ~ 1, 
                      q12 ==1 | q12 ==3 | q12==0 ~ 0),
  f_narrate=case_when(q15==1 ~ 1, 
                      q15 == 0 | q15 == 9 ~ 0),
  o_mention=case_when(q13 == 4 | q13 ==2 ~ 1,
                      q13 ==0 | q13==1 | q13 == 3 ~ 0),
  o_picture=case_when(q13==3 | q13==2 ~1,
                      q13==0 | q13==1 | q13==4 ~ 0),
  ad_tone=case_when(q14 == 2 ~ 1,
                    q14 == 3 ~ 2,
                    q14 == 1 ~ 3,
                    q14 ==0 | q14==4 ~ 4),
  prty_mn=case_when(q22==0 | q22==1 ~ 0,
                    q22==4 ~ 1,
                    q22 == 2 ~2,
                    q22 == 3 ~3),
  Party=case_when(q5==1 ~ "DEMOCRAT",
                  q5==2 ~ "REPUBLICAN",
                  q5 != 1 | q5 != 2 ~ "OTHER"),
  sponsor=case_when(sponsor ==1 | sponsor ==2 | sponsor ==9 | sponsor ==10 | sponsor == 11 | sponsor ==12 ~ 1,
                    sponsor ==3 | sponsor ==4 | sponsor ==13 | sponsor == 14 | sponsor ==15 | sponsor ==16 ~ 2,
                    sponsor == 7 | sponsor ==8 ~ 3,
                    sponsor ==5 | sponsor ==6 | sponsor ==17 | sponsor == 18 | sponsor ==80 ~ 4)
  ) %>% 
  select(-q5, -q12, -q13, -q14, -q15, -q20, -q21, -q22) %>% 
  relocate(Party, .after = len) %>% 
  rename(
    creative=custitle, 
    l=len,
    party=Party
  ) %>% 
  view()



##########Unlikely############

unprob_df_2000 <- df2000 %>% 
  filter(q32 != 50 & q33 != 50 & q34 != 50 & q35 != 50 & q32 != 51 & q33 != 51 & q34 != 51 & q35 != 51 & q32 != 52 & q33 != 52 & q34 != 52 & q35 != 52 & q32 != 53 & q33 != 53 & q34 != 53 & q35 != 53 & q32 != 54 & q33 != 54 & q34 != 54 & q35 != 54 & q32 != 55 & q33 != 55 & q34 != 55 & q35 != 55 & q32 != 59 & q33 != 59 & q34 != 59 & q35 != 59) %>% 
  select(custitle, len, q5, sponsor, q3, q12, q13, q14, q15, q20, q21, q22, q32, q33, q34, q35) %>% 
  filter(q3 == 95) %>% group_by(custitle, len, sponsor) %>%
  mutate(
    count = n(), 
    year=2000,
    f_mention=case_when(q12== 1 | q12== 4 ~ 1,
                      q12==0 | q12 ==3 ~ 0),
  f_picture=case_when(q12==2 | q12==4 ~ 1, 
                      q12 ==1 | q12 ==3 | q12==0 ~ 0),
  f_narrate=case_when(q15==1 ~ 1, 
                      q15 == 0 | q15 == 9 ~ 0),
  o_mention=case_when(q13 == 4 | q13 ==2 ~ 1,
                      q13 ==0 | q13==1 | q13 == 3 ~ 0),
  o_picture=case_when(q13==3 | q13==2 ~1,
                      q13==0 | q13==1 | q13==4 ~ 0),
  ad_tone=case_when(q14 == 2 ~ 1,
                    q14 == 3 ~ 2,
                    q14 == 1 ~ 3,
                    q14 ==0 | q14==4 ~ 4),
  prty_mn=case_when(q22==0 | q22==1 ~ 0,
                    q22==4 ~ 1,
                    q22 == 2 ~2,
                    q22 == 3 ~3),
  Party=case_when(q5==1 ~ "DEMOCRAT",
                  q5==2 ~ "REPUBLICAN",
                  q5 != 1 | q5 != 2 ~ "OTHER"),
  sponsor=case_when(sponsor ==1 | sponsor ==2 | sponsor ==9 | sponsor ==10 | sponsor == 11 | sponsor ==12 ~ 1,
                    sponsor ==3 | sponsor ==4 | sponsor ==13 | sponsor == 14 | sponsor ==15 | sponsor ==16 ~ 2,
                    sponsor == 7 | sponsor ==8 ~ 3,
                    sponsor ==5 | sponsor ==6 | sponsor ==17 | sponsor == 18 | sponsor ==80 ~ 4)
  ) %>% distinct() %>% select(-q5, -q12, -q13, -q14, -q15, -q20, -q21, -q22) %>% 
  relocate(Party, .after = len) %>% 
  rename(
    creative=custitle, 
    l=len,
    party=Party
  ) %>% select(year, count, creative, l, party, sponsor, f_mention, f_picture, f_narrate, o_mention, o_picture, ad_tone, prty_mn) %>% arrange(desc(count)) %>% 
  view()
  
  

# below is the list that is "unprobable" to contain the ads I think I need to watch
clean_df_2000_unprobably <- df2000 %>% 
  filter(q32 != 50 & q33 != 50 & q34 != 50 & q35 != 50 & q32 != 51 & q33 != 51 & q34 != 51 & q35 != 51 & q32 != 52 & q33 != 52 & q34 != 52 & q35 != 52 & q32 != 53 & q33 != 53 & q34 != 53 & q35 != 53 & q32 != 54 & q33 != 54 & q34 != 54 & q35 != 54 & q32 != 55 & q33 != 55 & q34 != 55 & q35 != 55 & q32 != 59 & q33 != 59 & q34 != 59 & q35 != 59) %>% 
  select(custitle, len, q3, q5, q32, q33, q34, q35) %>% 
  filter(q3== 95) %>% 
  group_by(custitle) %>% view()

initial_2000_join_unprobable <- clean_df_2000_unprobably %>% 
  group_by(custitle, len) %>%
  mutate(
    count = n(), 
    year=2000
  ) %>% 
distinct() %>% 
  select(year, count, custitle, len, q3, q5, q32, q33, q34, q35) %>% 
  arrange(desc(count)) %>% 
  view()

# 328 ads to NOT watch. 

df_2000_notlikely <- initial_2000_join_unprobable %>% mutate(
  party=case_when(q5==1 ~ "DEMOCRAT",
                  q5==2 ~ "REPUBLICAN",
                  q5 != 1 | q5 != 2 ~ "OTHER")
  ) %>% select(-q3, -q5, -q32, -q33, -q34, -q35) %>% 
   rename(
    creative=custitle, 
    l=len) %>% drop_na() %>% view()

```

```{r join_data_frames, include=FALSE, echo=FALSE, warning=FALSE}

# Here, bind the rows of all pertinent data frames and 
# then write to an excel file for future coding. 

# File for Likely
df_comb_init_cads <- bind_rows(df_2016, df_2012, df_2008, df_2004, df_2000) %>% view()
df_comb_init_cads %>% write_xlsx(here("data", "df_comb_init_cads.xlsx"))

# Revised File for Likely
revised_df_comb_init_cads <- bind_rows(df_2016, df_2012, df_2008, df_2004_revised, df_2000) %>% view()
revised_df_comb_init_cads %>% write_xlsx(here("data", "revised_df_comb_init_cads.xlsx"))

# File for Initial Unlikely File
df_comb_init_cads_unlikely <- bind_rows(df_2016_notlikely, df_2012_notlikely, df_2008_notlikely, df_2004_notlikely, df_2000_notlikely) %>% view() 
df_comb_init_cads_unlikely %>% write_xlsx(here("data", "df_comb_init_cads_unlikely.xlsx"))

## File for the Master Imagery Check; Have to Carefully Comb Through Years 2000, 2004, and 2008
ch6_master_imagery_check_roughdraft <- bind_rows(unprob_df_2016, unprob_df_2012, unprob_df_2008, unprob_df_2004, unprob_df_2000) %>% view()
ch6_master_imagery_check_roughdraft %>% write_xlsx(here("data", "ch6_master_imagery_roughdraft.xlsx"))

# Now, I use the Master Imagery File to Do Some More Data Sorting
# I produce a final excel file from which to bounce off the regression file

master_imageryDF <- read_csv(here("data", "ch6_Master_Imagery.csv")) %>% ungroup() %>% view()

refined_master_imagery_ch4 <- master_imageryDF %>% group_by(year) %>% arrange(year, desc(count)) %>% distinct(.keep_all=TRUE) %>% view()

refined_master_imagery_ch4 %>% write_xlsx(here("data", "refined_master_imagery_ch4.xlsx"))

```


# Section 2 : An airings-level Analysis


```{airings combined file}
#2000 Information
# This df is unique.  I only want presidential ads, so I have to filter only where #'q3'==95, which denotes a presidential ad. 

airings_2000 <- df_2000 %>% filter(q3 == 95) %>% select(spotdate, custitle, marketlo, stncalls, len) %>% rename(date=spotdate, creative=custitle, market=marketlo, station=stncalls, l=len) %>% mutate(
  dma=0, 
  Elec_Cycle=2000
) 
summary(airings_2000)
airings_2000 %>% write_csv(here("data", "airings_2000.csv"))

#2004 Ad Information

airings_2004 <- df_2004 %>% select(date, creative, market, station, spotleng) %>% rename(l=spotleng) %>% mutate(
  dma=0,
  Elec_Cycle=2004
) 
summary(airings_2004)
airings_2004 %>% write_csv(here("data", "airings_2004.csv"))

#2008 Ad Information

airings_2008 <- df_2008 %>% select(date, creative, market, station, l)
airings_2008 <- airings_2008 %>% mutate(
  dma=0, 
  Elec_Cycle=2008
) 
summary(airings_2008)

# there is one issue with the 2008 airings I need to fix.  
# Several hundred ads take on a value of market of 'Springfield, M' but that could # mean Springfield, MO or Springfield, MA.  
# Need to find all values of station that start with 'W' and assign those observations a value of market of 'Springfield, MA' and all that start with a 'K' a value of 'Springfield, MO'

airings_2008 <- airings_2008 %>% mutate(
  market = if_else(substr(station, 1, 1)=="K" & market=="Springfield, M", "Springfield, MO", market),
  market = if_else(substr(station, 1, 1)=="W" & market=="Springfield, M", "Springfield, MA", market) 
)

airings_2008 %>% write_csv(here("data", "airings_2008.csv"))

#2012 Ad Information
airings_2012 <- df_2012 %>% select(airdate, creative, market, station, l, dma) %>% mutate(
  Elec_Cycle=2012
) 
airings_2012 <- airings_2012 %>% rename(date=airdate)
summary(airings_2012)
airings_2012 %>% write_csv(here("data", "airings_2012.csv"))


#2016 Ad Information
airings_2016 <- df_2016 %>% select(airdate, creative, market, station, l, dma) %>% mutate(
  Elec_Cycle=2016
)
airings_2016 <- airings_2016 %>% rename(date=airdate)
summary(airings_2016)
airings_2016 %>% write_csv(here("data", "airings_2016.csv"))



## I need to fix the date variable for the 2008 airings file only
airings_2008 <- airings_2008 %>% mutate(
  conv.date=mdy(date)
)

# see what dates are the problem
airings_2008 %>% filter(is.na(conv.date)) %>% select(date, conv.date, creative, l) %>% group_by(creative) %>% distinct() %>% view()

# problem dates are 10/10/200 - 10/31/200
# problem dates are 11/10/200 - 11/30/200  (will become 2007)
# problem dates are 12/10/200 - 12/31/200  (will become 2007)

# first replace airings between 11/10/200 - 12/31/200 with their dates followed by 2007
airings_2008 <- airings_2008 %>% mutate(
  date=if_else(
    (substr(date, 1, 2) =="11" & substr(date, 7, 9) == "200" & is.na(conv.date)==TRUE), paste(substr(date, 1, 6), "2007"), date),
  date=if_else(
    (substr(date, 1, 2) =="12" & substr(date, 7, 9) == "200" & is.na(conv.date)==TRUE), paste(substr(date, 1, 6), "2007"), date)) 

airings_2008 <- airings_2008 %>% mutate(
  conv.date=mdy(date)
)

## now fix the date range of 10/10/200 - 10/31/200
airings_2008 <- airings_2008 %>% mutate(
  date=if_else(
     (substr(date, 1, 2) =="10" & substr(date, 7, 9) == "200" & is.na(conv.date)==TRUE & grepl("MCCAIN|OBAMA", airings_2008$creative)==TRUE),
     paste(substr(date, 1, 6), "2008"), date)) %>% mutate(
  date=if_else(
     (substr(date, 1, 2) =="10" & substr(date, 7, 9) == "200" & is.na(conv.date)==TRUE & grepl("MCCAIN|OBAMA", airings_2008$creative)==FALSE),
     paste(substr(date, 1, 6), "2007"), date)) 

airings_2008 <- airings_2008 %>% mutate(
  conv.date=mdy(date)
)


# Create a final airings only file from which to merge DMA - specific information


# bind rows and write a csv file of all election ad airings (ads_airings.csv)
airings_all <- bind_rows(airings_2000, airings_2004, airings_2008, airings_2012, airings_2016) 

airings_all %>% write_csv(here("data", "ads_airings.csv"))

```


```{airings merging data continued}

ch4_airings_df <- read_csv(here("data", "ads_airings.csv"))

# 4,706,974 total airings in the data frame

# drop the station variable
ch4_airings_df <- ch4_airings_df %>% select(-station)

### count the number of unique, distinct advertisements by name, election cycle, and length. 
ch4_airings_df %>% select(creative, Elec_Cycle, l) %>% distinct() %>% view()
###3668 ads

### count how many airings ran on cable = (34,906)
ch4_airings_df %>% filter(market %in% c("CABLE", "NATIONAL", "NATIONAL CABLE", "NATIONAL NETWORK"))

# convert to uppercase and drop ads that ran on cable
ch4_airings_df <- ch4_airings_df %>% mutate(
  ch4_airings_df, across(where(is.character), .fns = toupper)
  ) %>% filter(!market %in% c("CABLE", "NATIONAL", "NATIONAL CABLE", "NATIONAL NETWORK"))

# recount distinct ads by name, election cycle, length. 
ch4_airings_df %>% select(creative, Elec_Cycle, l) %>% distinct()
# count is now 3,516 ads.  This means that 152 unique 
# ad/creative/length identifiers ran on cable only.


# Now read in file that crosswalks market names with Media Market and Percent #Veteran Values

ch4_airings_media_markets_edits <- read_csv(here("data", "ads_airings_distinct_markets_edits.csv"))
summary(ch4_airings_media_markets_edits)

# drop cable options as a merger because I already dropped 
# cable from the airings df above

ch4_airings_media_markets_edits <- ch4_airings_media_markets_edits %>% filter(!market %in% c("CABLE", "NATIONAL", "NATIONAL CABLE", "NATIONAL NETWORK"))

# Now merge important files to create a DF that has airing,percent vetpop, and common media market name

ch4_airings_DMA_vet_pop <- inner_join(ch4_airings_df, ch4_airings_media_markets_edits, by="market")
ch4_airings_DMA_vet_pop <- ch4_airings_DMA_vet_pop %>% select(-market, -market_DMA)

# Now write to another CSV that I can grab quickly. 
ch4_airings_DMA_vet_pop %>% write_csv(here("data", "ads_airings_mkt_vet_pop.csv"))


```

# Pick up Mutating New Variables for Year-Polarization here. Also where you could read in data starting here.  

```{r airings analysis}

# First read in airings df.  Capitalize. Make an airing-Year variable and assign
# values of independent variables here. 

ch4_airings_master <- read_csv(here("data", "ads_airings_mkt_vet_pop.csv")) 
ch4_airings_master <- mutate(ch4_airings_master, across(where(is.character), .fns = toupper))
ch4_airings_master <- ch4_airings_master %>% mutate(
  Airing_Yr = year(date),
  house_polar = case_when(
    Airing_Yr== 2000 ~ 77.713,
    Airing_Yr == 2003 ~ 79.302,
    Airing_Yr == 2004 ~ 79.302,
    Airing_Yr == 2007 ~ 80.765,
    Airing_Yr == 2008 ~ 80.765,
    Airing_Yr == 2011 ~ 86.142,
    Airing_Yr == 2012 ~ 86.142,
    Airing_Yr == 2015 ~ 87.639,
    Airing_Yr == 2016 ~ 87.639,
    ),
  sen_polar = case_when(
    Airing_Yr== 2000 ~ 65.833,
    Airing_Yr == 2003 ~ 64.984,
    Airing_Yr == 2004 ~ 64.984,
    Airing_Yr == 2007 ~ 68.736,
    Airing_Yr == 2008 ~ 68.736,
    Airing_Yr == 2011 ~ 74.383,
    Airing_Yr == 2012 ~ 74.383,
    Airing_Yr == 2015 ~ 81.293,
    Airing_Yr == 2016 ~ 81.293,
  ),
  aff_polar = case_when(
    Airing_Yr== 2000 ~ 61.692,
    Airing_Yr == 2003  ~ 69.27,
    Airing_Yr == 2004  ~ 69.27,
    Airing_Yr == 2007 ~ 69.519,
    Airing_Yr == 2008 ~ 69.519,
    Airing_Yr == 2011 ~ 84.689,
    Airing_Yr == 2012 ~ 84.689,
    Airing_Yr == 2015 ~ 67.754,
    Airing_Yr == 2016 ~ 67.754,
  ),
  HostCasRate = case_when(
    Airing_Yr == 2000 ~ 1.23874924,
    Airing_Yr == 2003 ~ 21.92014883,
    Airing_Yr == 2004 ~ 52.0801226,
    Airing_Yr == 2007 ~ 61.97806503,
    Airing_Yr == 2008 ~ 25.1029256,
    Airing_Yr == 2011 ~ 31.31,
    Airing_Yr == 2012 ~ 21.4917871,
    Airing_Yr == 2015 ~ 1.750,
    Airing_Yr == 2016 ~ 1.229532,
  ),
  HostCasRateLagged = case_when(
    Airing_Yr == 2000 ~ 0,
    Airing_Yr == 2003 ~ 1.20,
    Airing_Yr == 2004 ~ 21.92014883,
    Airing_Yr == 2007 ~ 56.07,
    Airing_Yr == 2008 ~ 61.97806503,
    Airing_Yr == 2011 ~ 31.866,
    Airing_Yr == 2012 ~ 31.31,
    Airing_Yr == 2015 ~ 4.034,
    Airing_Yr == 2016 ~ 1.750,
  ),
  mil_prestige = case_when(
    Airing_Yr == 2000 ~ 64,
    Airing_Yr == 2003 ~ 82,
    Airing_Yr == 2004 ~ 75,
    Airing_Yr == 2007 ~ 69,
    Airing_Yr == 2008 ~ 71,
    Airing_Yr == 2011 ~ 78,
    Airing_Yr == 2012 ~ 75,
    Airing_Yr == 2015 ~ 72,
    Airing_Yr == 2016 ~ 73,
  ), 
  cong_prestige = case_when(
    Airing_Yr == 2000 ~ 24,
    Airing_Yr == 2003 ~ 29,
    Airing_Yr == 2004 ~ 30,
    Airing_Yr == 2007 ~ 14,
    Airing_Yr == 2008 ~ 12,
    Airing_Yr == 2011 ~ 12,
    Airing_Yr == 2012 ~ 73,
    Airing_Yr == 2015 ~ 8,
    Airing_Yr == 2016 ~ 9
  ),
  prty_ofc = case_when(      ## assigns 1 if party in office at start of year was D, and 0 if R
    Airing_Yr == 2000 ~ 1,
    Airing_Yr == 2003 ~ 0,
    Airing_Yr == 2004 ~ 0,
    Airing_Yr == 2007 ~ 0,
    Airing_Yr == 2008 ~ 0,
    Airing_Yr == 2011 ~ 1,
    Airing_Yr == 2012 ~ 1,
    Airing_Yr == 2015 ~ 1,
    Airing_Yr == 2016 ~ 1,
  ),
  prestige_gap = mil_prestige-cong_prestige
)
table(list(ch4_airings_master$Airing_Yr))
table(list(ch4_airings_master$house_polar))


### create intervals to separate primary vs general election ads, and then 
### create a primary variable that equals ==1 or 0.
### first date is Jan 1 of year before an election; second date is end of primary contest
### as per wikipedia
pri_00 <- interval(ymd("2000-01-01"), ymd("2000-06-06"))
pri_04 <- interval(ymd("2003-01-01"), ymd("2004-06-08"))
pri_08 <- interval(ymd("2007-01-01"), ymd("2008-06-03"))
pri_12 <- interval(ymd("2011-01-01"), ymd("2012-06-05"))
pri_16 <- interval(ymd("2015-01-01"), ymd("2016-06-07"))

ch4_airings_master <- ch4_airings_master %>% mutate(
  primary = case_when(
    date %within% pri_00 ~ 1,
    date %within% pri_04 ~ 1,
    date %within% pri_08 ~ 1,
    date %within% pri_12 ~ 1,
    date %within% pri_16 ~ 1,
  )) %>% mutate(
    primary = ifelse(is.na(primary), 0, primary)
  )


# Now read in commercial-level df.  Capitalize.     
ch4_ads_master <- read_csv(here("data", "ch4_ads_coded.csv"))
ch4_ads_master <- mutate(ch4_ads_master, across(where(is.character), .fns = toupper))


# More cleaning steps. 
ch4_ads_master <- ch4_ads_master [1:3666,] %>% select(year:missing) %>% rename(missing_ad=missing) %>% mutate_at(
  .vars = vars(missing_ad), 
  .funs = ~ case_when(is.na(.) ~ 0, TRUE ~1) 
) %>% mutate(
  can_vet = replace(can_vet, can_vet != 1, 0),
  partisan_act=case_when(
    vet_fam_end ==1 | vet_fam_atk ==1 | vet_fam_out_issues ==1 ~ 1, 
    vet_fam_end !=1 & vet_fam_atk!=1 & vet_fam_out_issues !=1 ~ 0 ),
  dummy_04=case_when(
    year == 2004 ~ 1, 
    year != 2004 ~0), 
  party_reg=case_when(
    party=="DEMOCRAT" ~ "DEMOCRAT",
    party=="REPUBLICAN" ~ "REPUBLICAN",
    (party!= "REPUBLICAN") & (party!= "DEMOCRAT") ~ "OTHER"
  ),
  party_reg_numeric=case_when(
    party_reg=="DEMOCRAT" ~ 1,
    party_reg=="REPUBLICAN" ~ 0,
    party_reg=="OTHER" ~2
  ))


# There are a couple of ads in the ad-specific data frame that have the same name but take on different values. I clean that up here.  
ch4_ads_master %>% select(year, creative, l) %>% distinct() %>% nrow()
ch4_ads_master %>% group_by(year, creative, l) %>% mutate(x=n()) %>% filter(x==2) %>% view()

ch4_ads_master <- ch4_ads_master %>% group_by(year, creative, l) %>% 
  mutate(
  count=max(count),
  f_picture = max(f_picture),
  o_mention = max(o_mention),
  prty_mn = max(prty_mn),
  def_vet_ad_theme = max(def_vet_ad_theme),
  img_likely = max(img_likely)
) %>% distinct()

ch4_ads_master %>% select(year, creative, l) %>% distinct()

# 3,664 ad-level information available for 3,516

# drop variables that I will not need and rename year to Elec_Cycle'  
ch4_ads_master <- ch4_ads_master %>% select(-count, -f_mention, -ad_purpose, -f_picture, -f_narrate, -o_mention, -o_picture, -ad_tone, -prty_mn, -finished, -img_likely, -notes) %>% rename(Elec_Cycle=year)


### now join data frames on year, creative, and l variables.  

ch4_POTUS_all_master <- full_join(ch4_airings_master, ch4_ads_master, by = c("Elec_Cycle", "creative", "l"))

ch4_POTUS_all_master %>% write_csv(here("data", "ch4_POTUS_airings_master.csv"))
```


```{r airings analysis for chapter 4}
### The above chunk creates the "master" file.  Begin with the true analysis portion here. 

ch4_airings_analysis <- read_csv(here("data", "ch4_POTUS_airings_master.csv")) %>% filter(missing_ad != 1) %>% select(-dma)

# Make some new variables. 
ch4_airings_analysis <- ch4_airings_analysis %>% mutate(
    mil_img = case_when(
    (vet_fam != 0) | (act_dty_img ==1 | vet_img ==1 | us_mil_hard_img ==1 | us_cmbt_img==1) ~ 1, 
  (vet_fam == 0) & (act_dty_img ==0 & vet_img ==0 & us_mil_hard_img ==0 & us_cmbt_img==0) ~ 0
),
  no_mil_img = case_when(
    (vet_fam != 1) & (act_dty_img !=1 & vet_img !=1 & us_mil_hard_img !=1 & us_cmbt_img!=1) ~ 1, 
  (vet_fam != 0) | (act_dty_img ==1 | vet_img ==1 | us_mil_hard_img ==1 | us_cmbt_img==1) ~ 0
  )
    ) 

# Drop NA values that are not matched up according to market, date, etc.
# This drops about 35k viewings.  
ch4_airings_analysis <- ch4_airings_analysis %>% drop_na()

### we have a total of 4,531,041 viewings to analyze across 3,414 unique ads.  
### This is pretty good. This should be viewed as a high percentage of a total of 
### 4,544,150 viewings for which we have information on the ads that are shown and for 
### which data is available.



ch4_airings_analysis %>% filter(can_vet==1) %>% select(creative, Elec_Cycle) %>% distinct() %>% view()


ch4_airings_analysis %>% filter(Elec_Cycle == 2016, party!= "DEMOCRAT", primary==1) %>% select(creative) %>% distinct() %>% view()

ch4_airings_overall_slim %>% 
  select_if(function(x) any(is.na(x))) %>% 
  summarise_each(funs(sum(is.na(.)))) %>% view()

# Let's start with some initial analysis.  What would be cool to find?
# Perhaps the overall percentage of act_dty_img, vet_img, us_mil_hard_img, us_cmbt_img, mil_img, vet_fam, def_vet_ad_theme. 

ch4_airings_overall_slim %>% group_by(Elec_Cycle) %>% summarize(prop_act_dty_img=mean(vet_img), prop_vet_img=mean(vet_img), prop_us_mil_hard_img=mean(us_mil_hard_img), prop_cmbt_img=mean(us_cmbt_img), prop_mil_img=mean(mil_img), prop_vet_fam=mean(vet_fam), prop_def_theme=mean(def_vet_ad_theme)) %>% arrange() %>% view()

# create a character string that has the media market names of these top 50 media markets. 

top_mkts_by_name <- c("LAS VEGAS, NV", "DENVER, CO", "CLEVELAND, OH", "TAMPA-SARASOTA, FL", "DES MOINES, IA-MO", "ORLANDO-DAYTONA BEACH, FL", "CEDAR RAPIDS, IA", "COLUMBUS, OH", "RENO, NV-CA", "CINCINATTI, OH", "WASHINGTON DC-MD-PA-VA-WV", "BOSTON, MA-NH", "NORFOLK, VA-NC", "TOLEDO, OH", "RICHMOND, VA", "DAVENPORT, IA-IL", "DAYTON, OH", "ROANOKE-LYNCHBURG, VA", "CHARLOTTE, NC", "COLORADO SPRINGS-PUEBLO, CO", "JACKSONVILLE, FL - BRUNSWICK, GA", "MIAMI-FORT LAUDERDALE, FL", "GRAND JUNCTION, CO", "WEST PALM BEACH, FL", "SIOUX CITY, IA-NE-SD", "FORT MEYERS-NAPLES, FL", "MILWAUKEE, WI", "RALEIGH-DURHAM, NC-VA", "YOUNGSTOWN, OH-PA", "GREEN BAY-APPLETON, WI", "GREENVILLE-SPARTANBURG, SC", "GREENSBORO-W.SALEM, NC", "HARRISBURG-LANCASTER, PA", "MADISON, WI", "PHILADELPHIA, PA-DE-NJ", "LACROSSE-EAU CLAIRE, WI", "GREENVILLE-NEW BERN-WASHINGTON, NC", "PITTSBURGH, PA-MD-WV", "GRAND RAPIDS-KALAMAZOO, MI", "ROCHESTER-MASON CITY, MN-IA", "BURLINGTON, VT", "WILKES BARRE-SCRANTON, PA", "ALBUQUERQUE-SANTA FE", "DETROIT, MI", "WAUSAU-RHINELANDER, WI", "CHARLOTTESVILLE, VA", "JOHNSTOWN-ALTOONA, PA", "PORTLAND-AUBURN, ME-NH-VT", "FLINT-SAGINAW, MI", "LANSING, MI")

ch4_airings_analysis %>% filter(media_market %in% top_mkts_by_name) %>% group_by(media_market) %>% summarize(prop_act_dty_img=mean(vet_img), prop_vet_img=mean(vet_img), prop_us_mil_hard_img=mean(us_mil_hard_img), prop_cmbt_img=mean(us_cmbt_img), prop_mil_img=mean(mil_img), prop_vet_fam=mean(vet_fam), prop_def_theme=mean(def_vet_ad_theme)) %>% arrange() %>% view()


mod1 <- glm(vet_img ~ percent_vet + house_polar + HostCasRateLagged + can_vet + party_reg + mil_prestige + can_vet_mention,
             family=binomial(link="logit"),
            data=ch4_airings_overall_slim
)

summary(mod1)





# Let's start with the two most boring elections, 2008 and 2012 and identify the 50 most competitive media 
# markets; that is, let's find out which media markets aired the most advertisements in each year and determine the range of ads that showed veteran, military imagery in each of these.  


# Begin with 2008 and 2012 together.  

# Identify which markets ran the most elections. 
comp_mkts_08 <- ch4_airings_analysis %>% filter(!Elec_Cycle %in% c(2000, 2004, 2016))%>% group_by(media_market) %>% 
  summarize(
  count=n()
) %>% arrange(count)


# create a character string that has the media market names of these top 50 media markets. 
top_mkts_by_name_08 <- c("LAS VEGAS, NV", "DENVER, CO", "CLEVELAND, OH", "TAMPA-SARASOTA, FL", "DES MOINES, IA-MO", "ORLANDO-DAYTONA BEACH, FL", "CEDAR RAPIDS, IA", "COLUMBUS, OH", "RENO, NV-CA", "CINCINATTI, OH", "WASHINGTON DC-MD-PA-VA-WV", "BOSTON, MA-NH", "NORFOLK, VA-NC", "TOLEDO, OH", "RICHMOND, VA", "DAVENPORT, IA-IL", "DAYTON, OH", "ROANOKE-LYNCHBURG, VA", "CHARLOTTE, NC", "COLORADO SPRINGS-PUEBLO, CO", "JACKSONVILLE, FL - BRUNSWICK, GA", "MIAMI-FORT LAUDERDALE, FL", "GRAND JUNCTION, CO", "WEST PALM BEACH, FL", "SIOUX CITY, IA-NE-SD", "FORT MEYERS-NAPLES, FL", "MILWAUKEE, WI", "RALEIGH-DURHAM, NC-VA", "YOUNGSTOWN, OH-PA", "GREEN BAY-APPLETON, WI", "GREENVILLE-SPARTANBURG, SC", "GREENSBORO-W.SALEM, NC", "HARRISBURG-LANCASTER, PA", "MADISON, WI", "PHILADELPHIA, PA-DE-NJ", "LACROSSE-EAU CLAIRE, WI", "GREENVILLE-NEW BERN-WASHINGTON, NC", "PITTSBURGH, PA-MD-WV", "GRAND RAPIDS-KALAMAZOO, MI", "ROCHESTER-MASON CITY, MN-IA", "BURLINGTON, VT", "WILKES BARRE-SCRANTON, PA", "ALBUQUERQUE-SANTA FE", "DETROIT, MI", "WAUSAU-RHINELANDER, WI", "CHARLOTTESVILLE, VA", "JOHNSTOWN-ALTOONA, PA", "PORTLAND-AUBURN, ME-NH-VT", "FLINT-SAGINAW, MI", "LANSING, MI")

vet_img_08_top <- ch4_airings_analysis %>% filter(!Elec_Cycle %in% c(2000, 2004, 2016), media_market %in% top_mkts_by_name_08) %>% group_by(media_market) %>% summarize(prop_vet_img=mean(vet_img)) %>% arrange(prop_vet_img)

# filter through these media markets and obtain the percentage of ads featuring vets in these media markets.

# Now move to only 2016. 

comp_mkts_16 <- ch4_airings_analysis %>% filter(Elec_Cycle %in% c(2016))%>% group_by(media_market) %>% 
  summarize(
  count=n()
) %>% arrange(count)

# create a character string that has the media market names of these top 50 media markets. 

top_mkts_by_name_16 <- comp_mkts_16$count

```

### State Polarization Effort

``` {r state polar}

load("/Users/petererickson/Documents/Wisconsin Academics/Dissertation/dissertation/data/shor-mccarty-state-polar.rdata")

summary(table)

state_polar <- table %>% select(st, year, h_diffs, s_diffs) %>% filter(year %in% c("2000", "2003", "2004", "2007", "2008", "2011", "2012", "2015", "2016"))

```


``` {r county level voting data}

cty_vote <- read_csv(here("data", "countypres_2000-2020.csv"))

```}



